# TimeLine

- [x] 框架
  - [x] config文件的创建和读取
  - [x] 读取照片
    - [x] 找到两个数据集中相同的照片
    - [x] 根据照片名字得到car pose和camera pose
    - [x] 设置内参矩阵
    - [x] 按顺序读取某一个record的照片
    - [x] 返回函数：返回一个字典(包含camera pose, 是否有car pose，id, rgb图, 深度图等信息)
  - [x] 创建多个线程
  
- [ ] 优化线程
  - [x] theseus图优化数据结构
  - [ ] theseus图优化计算函数 
  
- [ ] 将nerfstudio嵌入框架
  - [x] 尝试单进程融入
  
  - [ ] 将apollo数据集应用于其中
  
  - [x] 解决nerfstudio_collate.py问题
  
    在主进程调用nerfstudio就可以运行，但是在子进程不行(原因应该是pytorch的问题)
  
  - [ ] 单独调用nerfstudio各个模块
  
  - [ ] 将已有的background和object渲染模型改写进nerfstudio
  
  - [ ] 把obj-rendering换成[ssd-nerf](https://github.com/Lakonik/SSDNeRF)
  


# 环境配置

```shell
# 基本环境
pip install cython # 安装apollo数据集自带的库需要用到(在car_instance文件夹中安装)
# 安装apollo数据集的c++库需要sudo,如果和当前conda环境不一致需要用如下命令安装
sudo -E env "PATH=$PATH" bash install.sh
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
pip install numpy scipy matplotlib 
pip install opencv-python

# 安装theseus
## 安装前置库Dispenso,OpenBLAS,BaSpaCho
## 都只用sudo make install安装即可
## 从git官网下载最新版本theseus
git clone https://github.com/facebookresearch/theseus.git && cd theseus
BASPACHO_ROOT_DIR=/home/yang/3rdLibrary/baspacho pip install -e .
```



# 运行

```
python slam_system.py --config ./configs/apollo.yaml
```

# Debug

- 创建launch.json

  ```json
  {
      // Use IntelliSense to learn about possible attributes.
      // Hover to view descriptions of existing attributes.
      // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
      "version": "0.2.0",
      "configurations": [
          {
              "name": "Python: Current File",
              "type": "python",
              "request": "launch",
              "program": "${file}",
              "console": "integratedTerminal",
              "justMyCode": true,
              "args": [
                  "--config","./configs/apollo.yaml"
              ]
          }
      ]
  }
  ```

- 对主文件slam_system.py进行debug



# 3rdLib

## NerfStudio

### 1. 安装

参照[git官网](https://github.com/nerfstudio-project/nerfstudio/)来安装：

1. 在conda环境中安装python>=3.8和cuda11.8

2. 安装tiny-cuda-nn

   ```shell
   conda install -c "nvidia/label/cuda-11.8.0" cuda-toolkit
   pip install ninja git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch
   ```

3. 下载安装nerfstudio

   ```shell
   git clone https://github.com/nerfstudio-project/nerfstudio.git
   cd nerfstudio
   pip install --upgrade pip setuptools
   pip install -e .
   ```

### 2. 运行

使用nerfacto

```shell
# Download some test data:
ns-download-data nerfstudio --capture-name=poster
# Train model
ns-train nerfacto --data data/nerfstudio/poster
# 根据pyproject.toml可知，这里的ns-train就是调用了nerfstudio.scripts.train这个.py文件
# 所以运行如下命令一样可以训练
python train.py nerfacto --data ../../data/nerfstudio/poster 
```

使用neusfacto

```shell
# 下载数据集
ns-download-data sdfstudio --dataset-name sdfstudio-demo-data
# 训练模型
ns-train neus-facto --pipeline.model.sdf-field.inside-outside=False sdfstudio-data --data=data/sdfstudio-demo-data/dtu-scan65
# 直接用.py
python train.py neus-facto --pipeline.model.sdf-field.inside-outside=False sdfstudio-data --data=/home/yang/Desktop/SLAM_Code_Learning/nerfstudio/data/sdfstudio-demo-data/dtu-scan65
```

- 对于基于sdf的模型如neusfacto和neus，需要对客户数据进行预处理

  参考[issue1732](https://github.com/nerfstudio-project/nerfstudio/issues/1732#:~:text=Hi%20so%20you,get%20things%20preprocessed.)

- 关于nerfacto和neusfacto通用dataset的一些讨论：[issue2023](https://github.com/nerfstudio-project/nerfstudio/issues/2023)

#### 2.1 cofig输出

```shell
TrainerConfig(
    _target=<class 'nerfstudio.engine.trainer.Trainer'>,
    output_dir=PosixPath('outputs'),
    method_name='neus-facto',
    experiment_name=None,
    project_name='nerfstudio-project',
    timestamp='2024-01-20_165601',	# ! {timestamp}
    machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),
    logging=LoggingConfig(
        relative_log_dir=PosixPath('.'),
        steps_per_log=10,
        max_buffer_size=20,
        local_writer=LocalWriterConfig(
            _target=<class 'nerfstudio.utils.writer.LocalWriter'>,
            enable=True,
            stats_to_track=(
                <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,
                <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,
                <EventName.CURR_TEST_PSNR: 'Test PSNR'>,
                <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,
                <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,
                <EventName.ETA: 'ETA (time)'>
            ),
            max_log_size=10
        ),
        profiler='basic'
    ),
    viewer=ViewerConfig(
        relative_log_filename='viewer_log_filename.txt',
        websocket_port=None,
        websocket_port_default=7007,
        websocket_host='0.0.0.0',
        num_rays_per_chunk=32768,
        max_num_display_images=512,
        quit_on_train_completion=False,
        image_format='jpeg',
        jpeg_quality=75,
        make_share_url=False,
        camera_frustum_scale=0.1,
        default_composite_depth=True
    ),
    pipeline=VanillaPipelineConfig(
        _target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>,
        datamanager=VanillaDataManagerConfig(
            _target=nerfstudio.data.datamanagers.base_datamanager.VanillaDataManager[nerfstudio.data.datasets.sdf_datase
t.SDFDataset],
            data=PosixPath('/home/yang/Desktop/SLAM_Code_Learning/nerfstudio/data/nerfstudio/poster'),# ! data=None
            masks_on_gpu=False,
            images_on_gpu=False,
            dataparser=NerfstudioDataParserConfig(
                _target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>,
                data=PosixPath('.'),
                scale_factor=1.0,
                downscale_factor=None,
                scene_scale=1.0,
                orientation_method='up',
                center_method='poses',
                auto_scale_poses=True,
                eval_mode='fraction',
                train_split_fraction=0.9,
                eval_interval=8,
                depth_unit_scale_factor=0.001
            ),
            train_num_rays_per_batch=2048,
            train_num_images_to_sample_from=-1,
            train_num_times_to_repeat_images=-1,
            eval_num_rays_per_batch=2048,
            eval_num_images_to_sample_from=-1,
            eval_num_times_to_repeat_images=-1,
            eval_image_indices=(0,),
            collate_fn=<function nerfstudio_collate at 0x7ff24c0e3280>,
            camera_res_scale_factor=1.0,
            patch_size=1,
            camera_optimizer=None,
            pixel_sampler=PixelSamplerConfig(
                _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,
                num_rays_per_batch=4096,
                keep_full_image=False,
                is_equirectangular=False,
                fisheye_crop_radius=None
            )
        ),
        model=NeuSFactoModelConfig(
            _target=<class 'nerfstudio.models.neus_facto.NeuSFactoModel'>,
            enable_collider=True,
            collider_params={'near_plane': 2.0, 'far_plane': 6.0},
            loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},
            eval_num_rays_per_chunk=2048,
            prompt=None,
            near_plane=0.05,
            far_plane=4.0,
            far_plane_bg=1000.0,
            background_color='black',
            use_average_appearance_embedding=False,
            eikonal_loss_mult=0.1,
            fg_mask_loss_mult=0.01,
            mono_normal_loss_mult=0.0,
            mono_depth_loss_mult=0.0,
            sdf_field=SDFFieldConfig(
                _target=<class 'nerfstudio.fields.sdf_field.SDFField'>,
                num_layers=2,
                hidden_dim=256,
                geo_feat_dim=256,
                num_layers_color=2,
                hidden_dim_color=256,
                appearance_embedding_dim=32,
                use_appearance_embedding=False,
                bias=0.5,
                geometric_init=True,
                inside_outside=True,
                weight_norm=True,
                use_grid_feature=True,
                divide_factor=2.0,
                beta_init=0.8,
                encoding_type='hash',
                num_levels=16,
                max_res=2048,
                base_res=16,
                log2_hashmap_size=19,
                features_per_level=2,
                use_hash=True,
                smoothstep=True
            ),
            background_model='none',
            num_samples_outside=32,
            periodic_tvl_mult=0.0,
            overwrite_near_far_plane=False,
            num_samples=64,
            num_samples_importance=64,
            num_up_sample_steps=4,
            base_variance=64,
            perturb=True,
            num_proposal_samples_per_ray=(256, 96),
            num_neus_samples_per_ray=48,
            proposal_update_every=5,
            proposal_warmup=5000,
            num_proposal_iterations=2,
            use_same_proposal_network=False,
            proposal_net_args_list=[
                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 64},
                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256}
            ],
            interlevel_loss_mult=1.0,
            use_proposal_weight_anneal=True,
            proposal_weights_anneal_slope=10.0,
            proposal_weights_anneal_max_num_iters=1000,
            use_single_jitter=True
        )
    ),
    optimizers={
        'proposal_networks': {
            'optimizer': AdamOptimizerConfig(
                _target=<class 'torch.optim.adam.Adam'>,
                lr=0.01,
                eps=1e-15,
                max_norm=None,
                weight_decay=0
            ),
            'scheduler': MultiStepSchedulerConfig(
                _target=<class 'nerfstudio.engine.schedulers.MultiStepScheduler'>,
                max_steps=20001,
                gamma=0.33,
                milestones=(10000, 1500, 18000)
            )
        },
        'fields': {
            'optimizer': AdamOptimizerConfig(
                _target=<class 'torch.optim.adam.Adam'>,
                lr=0.0005,
                eps=1e-15,
                max_norm=None,
                weight_decay=0
            ),
            'scheduler': CosineDecaySchedulerConfig(
                _target=<class 'nerfstudio.engine.schedulers.CosineDecayScheduler'>,
                warm_up_end=500,
                learning_rate_alpha=0.05,
                max_steps=20001
            )
        },
        'field_background': {
            'optimizer': AdamOptimizerConfig(
                _target=<class 'torch.optim.adam.Adam'>,
                lr=0.0005,
                eps=1e-15,
                max_norm=None,
                weight_decay=0
            ),
            'scheduler': CosineDecaySchedulerConfig(
                _target=<class 'nerfstudio.engine.schedulers.CosineDecayScheduler'>,
                warm_up_end=500,
                learning_rate_alpha=0.05,
                max_steps=20001
            )
        }
    },
    vis='viewer',
    data=PosixPath('/home/yang/Desktop/SLAM_Code_Learning/nerfstudio/data/nerfstudio/poster'), # ! 普通字符串''
    prompt=None,
    relative_model_dir=PosixPath('nerfstudio_models'),
    load_scheduler=True,
    steps_per_save=2000,
    steps_per_eval_batch=5000,
    steps_per_eval_image=5000,
    steps_per_eval_all_images=1000000,
    max_num_iterations=20001,
    mixed_precision=False,
    use_grad_scaler=False,
    save_only_latest_checkpoint=True,
    load_dir=None,
    load_step=None,
    load_config=None,
    load_checkpoint=None,
    log_gradients=False,
    gradient_accumulation_steps={}
)
```



### 3. Pipelines

参考：[官方文档](https://docs.nerf.studio/developer_guides/pipelines/index.html)

![pipeline figure](https://cdn.jsdelivr.net/gh/Fernweh-yang/ImageHosting@main/img/nerfstudio_pipeline.png)

NerfStudio的目标就是把所有的nerf算法实现流程都用上面这个pipeline来实现，这个Pipeline主要由2个模块组成：

1. **DataManager**

   负责加载局数据并生成光线RayBundle和光线真值RayGT

   - 光线RayBundle描述了光线起点和方向，是模型Model的输入，在训练training和推断inference阶段都需要。
   - 光线真值RayGT包含了必要的GT值(pixel values等)，只在训练时使用，用于在loss dict中计算loss

   目前`nerfstudio`中所有的nerf算法用的都是`VanillaDataManager()`

2. **DataParser**

   dataparser返回值是`DataparserOutputs`类，会把各种数据转换成一个轻量级的通用格式，最后会被Pytorch的`Datasets`和`Dataloaders`读取。

   `nerfstudio`中各个算法都有各自的`DataParser`类实现

3. **Models**

   model也就是不同nerf论文中method部分的实现。

   model会在输入的RayBundle上采样，并返回每个光线的渲染值。

4. **Field**

   Field是model的一个组成部分，用于将一个空间部分(a region of space)和一些量(quantity)联系起来。通常输入是3d location和 viewing direction，输出是密度density和颜色color

5. **Pipeline**

   pipeline包含所有运行一个nerf算法的代码。


### 4. 使用自定义的数据集

根据[文档介绍](https://docs.nerf.studio/quickstart/custom_dataset.html)在nerfstudio中使用其他数据集，需要用他们的[scripts](https://github.com/nerfstudio-project/nerfstudio/blob/main/nerfstudio/scripts/process_data.py)完成如下操作：

1. 使用colmap来计算相机位姿
2. 转换成nerfstudio可以读取的格式

命令：[参考](https://docs.nerf.studio/reference/cli/ns_process_data.html#images)

```
ns-process-data {video,images,polycam,record3d} --data {DATA_PATH} --output-dir {PROCESSED_DATA_DIR}
```



## jaxtyping

在nerfstudio中有用到这个库。

根据[git官网](https://github.com/google/jaxtyping)介绍：是一个用于给[jax](https://jax.readthedocs.io/en/latest/index.html)数组类型, pytorch, numpy和 tensorflow做 **标注(annotate**) 和 **运行时类型检测(runtime type-checking** ) 的工具

> Just After eXceution（**JAX**）是CPU、GPU和TPU上的NumPy。它是一个用于高性能数值计算的Python库，特别是机器学习研究。

[文档](https://docs.kidger.site/jaxtyping/)

- 安装：

  ```
  pip install jaxtyping
  ```

- 例子：

  ```python
  # 在函数定义时写好，相当于在为数据类型做标注annotate
  from jaxtyping import Array, Float, PyTree, jaxtyped
  
  # 加了装饰器后，当调用下面函数时，会自动检查数据类型是否一致runtime type-checking
  # Use your favourite typechecker: usually one of the two lines below.
  from typeguard import typechecked as typechecker
  from beartype import beartype as typechecker
  
  
  # 例子1： 创建一个dtype=float类型的数组array，数组形状shape=dim1 x dim2
  # Accepts floating-point 2D arrays with matching axes
  # 形状可以是固定的数字如"28 28"，也可以是像这里的变量
  @jaxtyped(typechecker=typechecker)
  def matrix_multiply(x: Float[Array, "dim1 dim2"],
                      y: Float[Array, "dim2 dim3"]
                    ) -> Float[Array, "dim1 dim3"]:
      ...
  
  # 例子2： 为NumPy, TensorFlow, and PyTorch做类型检测：
  Float[np.ndarray, "..."]
  Float[tf.Tensor, "..."]
  Float[torch.Tensor, "..."]
      
      
  # 例子3： 创建一个PyTree类型的变量，int表示这个树的叶子数据类型
  def accepts_pytree_of_ints(x: PyTree[int]):
      ...
  
  def accepts_pytree_of_arrays(x: PyTree[Float[Array, "batch c1 c2"]]):
      ...
  ```

  

## toml

`.toml` 文件是一种配置文件格式，其名称来源于 "Tom's Obvious Minimal Language"，是一种易于阅读和编写的数据序列化语言。

Toml 旨在成为配置文件的一种简洁而直观的格式，它采用了键值对的结构，并支持嵌套、数组和其他复杂数据结构。

例子：

```python
import toml

# 例1：读取 Toml 文件
with open('your_file.toml', 'r') as file:
    data = toml.load(file)
print(data)

# 例2： 将字典写入Toml文件
data = {'key1': 'value1', 'key2': {'nested_key': 'nested_value'}}
with open('output_file.toml', 'w') as file:
    toml.dump(data, file)
```

