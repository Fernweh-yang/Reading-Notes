# 

# 一、杂七杂八的概念

## 1. 各种矩阵

### 1.1 正交矩阵

orthogonal matrix 

如果$AA^T=E\ 或\ A^TA=E$，那么$A和A^T$都是正交矩阵

### 1.2 奇异矩阵

singular matrix

如果矩阵的秩rank不是满秩，那么它就是奇异矩阵。

判断：

1. 看这个矩阵是否是方阵（如果行列数不相等，就谈不上奇异矩阵和非奇异矩阵）
2. 如果是方阵，再算det(A),若为0则为奇异矩阵



### 1.3 反对称矩阵

Skew-symmetric Matrix

向量外积可写成：
$$
a\times b=\left |\begin{array}{cccc}
e_1 & e_2 & e_3 \\
a_1 & a_2 & a_3  \\
b_1 & b_2 & b_3 \\
\end{array}\right|=\left [\begin{array}{cccc}
a_2b_3-a_3b_2 \\
a_3b_1-a_1b_3 \\
a_1b_2-a_2b_1 \\
\end{array}\right]=\left [\begin{array}{cccc}
0 & -a_3   & a_2 \\
a_3 & 0 & -a_1  \\
-a_2 & a_1 & 0 \\
\end{array}\right]b=a^\wedge b
$$
这样就把 向量外积运算 转换成了 矩阵与向量乘法。

这也表示了任意向量都对应着一个唯一的反对称矩阵Skew-symmetric Matrix:
$$
a^\wedge=\left [\begin{array}{cccc}
0 & -a_3   & a_2 \\
a_3 & 0 & -a_1  \\
-a_2 & a_1 & 0 \\
\end{array}\right]
$$

- 反对称矩阵有如下性质：
  - $A^T=-A$
  - 若A为反对称矩阵，B为对称矩阵,即$A^T=-A,B^T=B$
    - 那么$(AB-BA)^T=AB-BA$,即也是对称矩阵

### 1.4 雅可比矩阵

Jacobian Matrix

- 非线性的变换在局部具有线性的性质，雅可比矩阵解决了**非线性函数的求导问题**，将非线性问题局部转换为线性问题。

- 非线性函数**F**：$R_n->R_m$是一个从n维欧氏空间映射到m维欧氏空间的函数。

    $$
    J= \left\{
     \begin{matrix}
     \frac{\partial y_1}{\partial x_1}           & \cdots & \frac{\partial y_1}{\partial x_n}        \\   
     \vdots   & \ddots & \vdots   \\
     \frac{\partial y_m}{\partial x_n}  & \cdots & \frac{\partial y_m}{\partial x_n} 
     \end{matrix}
     \right\}
     =J_F(x_1,..,x_n)=\frac{\partial(y_1,...,y_m)}{\partial(x_1,...,x_n)}
    $$
    
    - 如果x是n维空间中1点，一个微小距离外的点$x+\delta$,有：
      $$
      F(x+\delta)=F(x)+J_F(x)\delta
      $$
      $J_F(p)$就是在x点的导数
    
      $J_F(p)$也表示了F这个非线性函数在点x附近的**最优线性逼近**

### 1.5 伴随矩阵

Adjugate matrix

由代数余子式Algebraic cofactor组成，用于求解矩阵的逆，和逆矩阵只差一个系数
$$
A^*=\left [\begin{array}{cccc}
A_{11} & A_{21} & \cdots & A_{n1} \\
A_{12} & A_{22} & \cdots & A_{n2} \\
\cdots & \cdots & \cdots & \cdots \\
A_{1n} & A_{2n} & \cdots & A_{nn} \\
\end{array}\right]\\
$$

- $A_{ij}$是矩阵A各个元素的代数余子式：
  - 将$A_{ij}$所在的第i和第j行划掉后，留下来n-1阶矩阵的**行列式**就是$A_{ij}$的余子式
  - 余子式乘上$-1^{i+j}$后即为代数余子式

## 2. 秩，逆和转置

Rank, Inverse and Transpose

- **秩**:

  秩是经矩阵（线性变化后）列空间的维数

  比如：

  - Rank=1:一维，变换结果为一条直线
  - Rank=2:二维，变换结果为一个平面
    - 若是2x2的矩阵，称为满秩
    - 若是3x3的矩阵，说明经该矩阵变换后会压缩一个维度。此时det(A)=0

- **逆**：

  $AA^{-1}=E$

  用伴随矩阵求逆：
  $$
  A^{-1}=\frac{1}{|A|}A^*
  $$

  - $A^*$是矩阵A的伴随矩阵

- **转置**：

  即行变成列，列变成行
  $$
  A=\left [\begin{array}{cccc}
  a_{11} & a_{12} & \cdots & a_{1n} \\
  a_{21} & a_{22} & \cdots & a_{2n} \\
  \cdots & \cdots & \cdots & \cdots \\
  a_{m1} & a_{m2} & \cdots & a_{mn} \\
  \end{array}\right]
  \\\\
  A^T=\left [\begin{array}{cccc}
  a_{11} & a_{21} & \cdots & a_{m1} \\
  a_{12} & a_{22} & \cdots & a_{m2} \\
  \cdots & \cdots & \cdots & \cdots \\
  a_{1n} & a_{2n} & \cdots & a_{mn} \\
  \end{array}\right]\\
  $$

  - $A和A^T$有同样的秩
  - $(Ax)^Ty$ 等价于 $x^T(A^Ty)$
  - 若$A=A^T$，那么A是一个对称矩阵

## 3. Ax=b 求解

- 若rank(A) < rank(A|b)，则该线性方程为超定方程，无解。（但是可以有最小二乘解
- 若rank(A) = rank(A|b)，则该线性方程组有解：在此基础上，若rank < A的列数（即变量的个数），则为欠定方程，有无穷解；若rank = A的列数，则为适定方程，具有唯一解。

## 4. 零空间

Null space

零空间指像为0的原像空间：$\{x|Ax=0\}$，零空间也称为核core

所以一个矩阵(线性映射)A的零空间就是方程Ax=0的所有解x的集合

## 5. 特征值分解：

Eigen decomposition

参考：https://zhuanlan.zhihu.com/p/69540876

- 目的：

  - 节省存储：一个矩阵分解成3个小矩阵
  - 降维：主成分分析PCA
  - 求Moore-Penrose伪逆

- 分解式：
  $$
  A=Q\Lambda Q^T
  $$

  - $Q$:A的特征向量组成的正交矩阵
  - $\Lambda$:特征值组成的对角矩阵

- 被特征分解的前提：
  - 必须是方阵，否则不存在特征值
  - 需要有n个线性无关的特征向量，否则没有特征向量Q的逆矩阵

## 6. 奇异值分解

Singular Value Decomposition（SVD）

- 目的：

  - 去噪：小奇异值很有大概率上是噪声，因此可以去掉

- 分解式：
  $$
  A=U\Sigma V^{-1}=U\Sigma V^T
  $$

  - $U$:m*m的正交矩阵
  - $\Sigma$:m*n的对角矩阵，由奇异值组成
  - $V$:n*n的正交矩阵

- 一些概念：
  - 可以借助SVD找到4个[基本子空间](https://zhuanlan.zhihu.com/p/34056351)(row space, null space,column space和left null space)
  - 奇异值必须≥0